{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6SfMLdA0VgG"
   },
   "source": [
    "# XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvpA3yFz0VgI"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import json, matplotlib\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 5)\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GIo4Yt-0VgX"
   },
   "source": [
    "## Función de activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oXn64F40VgZ"
   },
   "outputs": [],
   "source": [
    "# Devuelve la función logística evaluada\n",
    "# componente por componente\n",
    "def logistica(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "## Función que, dado un arreglo de valores z\n",
    "## calcula el valor de la derivada para cada entrada.\n",
    "def derivadaLogistica(z):\n",
    "    g = logistica(z)\n",
    "    return g * (1 - g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GIo4Yt-0VgX"
   },
   "source": [
    "## Función de perdida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_cross_entropy(predictions, targets):\n",
    "    #predictions = predictions[0]\n",
    "    #targets = targets[0]\n",
    "    N = predictions.shape[0]\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(N):\n",
    "        t_i, p_i = targets[i], predictions[i]\n",
    "        sum += t_i * np.log(p_i) + (1 - t_i) * np.log(1 - p_i)\n",
    "        \n",
    "    return - sum / N\n",
    "\n",
    "def bin_cross_entropy_derivate(predictions, targets):\n",
    "    #predictions = predictions[0]\n",
    "    #targets = targets[0]\n",
    "    N = predictions.shape[0]\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(N):\n",
    "        t_i, p_i = targets[i], predictions[i]\n",
    "        sum += (p_i - t_i) / (p_i ( 1 - p_i))\n",
    "        \n",
    "    return sum / N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hhk9wFG90Vgj"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Red neuronal\n",
    "La red implementa encadenamiento hacia adelante (para evaluar) y hacia atrás (para entrenarse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_T_D0r3s0Vgk"
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0J78Lgya0Vgo"
   },
   "outputs": [],
   "source": [
    "class XOR:\n",
    "    def __init__(self):\n",
    "        self.Theta_0 = np.random.random((2,3))\n",
    "        self.Theta_1 = np.random.random((1,3))\n",
    "    \n",
    "    def feedForward(self, X, vector = None):\n",
    "        \"\"\" Calcula las salidas, dados los datos de entrada. \"\"\"\n",
    "        if vector is None:\n",
    "            Theta_0 = self.Theta_0\n",
    "            Theta_1 = self.Theta_1\n",
    "        else:\n",
    "            Theta_0, Theta_1 = self.reconstructMatrices(vector)\n",
    "        \n",
    "        self.A0 = np.vstack((np.ones((1, X.shape[0])), X.T))\n",
    "        self.Z1 = np.dot(Theta_0, self.A0)\n",
    "        self.A1 = np.vstack((np.ones((1, self.Z1.shape[1])), logistica(self.Z1)))\n",
    "        self.Z2 = np.dot(Theta_1, self.A1)\n",
    "        self.A2 = logistica(self.Z2)\n",
    "        \n",
    "    def backPropagate(self, X, Y):\n",
    "        \"\"\" Calcula el error y su gradiente,\n",
    "        dados los pesos actuales de la red y los resultados\n",
    "        esperados.\n",
    "        \"\"\"\n",
    "        self.feedForward(X)\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        self.error = bin_cross_entropy(self.A2, Y.T)\n",
    "        Delta_2 = (Y.T - self.A2) * derivadaLogistica(self.Z2)\n",
    "        \n",
    "        self.Grad_1 = - np.dot(Delta_2, self.A1.T) / m\n",
    "        \n",
    "        Delta_1 = np.dot(self.Theta_1[:,1:].T, Delta_2) * derivadaLogistica(self.Z1)\n",
    "        self.Grad_0 = - np.dot(Delta_1, self.A0.T) / m\n",
    "        \n",
    "    def calcError(self, X, Y, vector):\n",
    "        \"\"\"\n",
    "        Calcula el error que se cometería utilizando los pesos en 'vector'.\n",
    "        \"\"\"\n",
    "        self.feedForward(X, vector)\n",
    "        return bin_cross_entropy(self.A2, Y.T)\n",
    "    \n",
    "    def vectorWeights(self):\n",
    "        \"\"\"\n",
    "        Acomoda a todos los parámetros en las matrices de pesos, en un solo vector.\n",
    "        \"\"\"\n",
    "        vector = np.vstack((self.Theta_0.reshape((self.Theta_0.size, 1)),\n",
    "                          self.Theta_1.reshape((self.Theta_1.size, 1))))\n",
    "        #print(self.Theta_0, self.Theta_1, vector)\n",
    "        return vector\n",
    "    \n",
    "    def reconstructMatrices(self, vector):\n",
    "        \"\"\"\n",
    "        Dado un vector, rearma matrices del tamaño de las matrices de pesos.\n",
    "        \"\"\"\n",
    "        M0 = vector[0:self.Theta_0.size].reshape(self.Theta_0.shape)\n",
    "        M1 = vector[self.Theta_0.size:].reshape(self.Theta_1.shape)\n",
    "        return M0, M1\n",
    "        \n",
    "    def approxGradient(self, X, Y):\n",
    "        \"\"\"\n",
    "        Aproxima el valor del gradiente alrededor de los pesos actuales,\n",
    "        perturbando cada valor, uno por uno.\n",
    "        \"\"\"\n",
    "        vector = self.vectorWeights().copy()\n",
    "        approx = np.zeros(vector.shape)\n",
    "        perturb = np.zeros(vector.shape)\n",
    "        epsilon = 0.0001\n",
    "        \n",
    "        for i in range(len(vector)):\n",
    "            perturb[i] = epsilon\n",
    "            loss1 = self.calcError(X, Y, vector - perturb)\n",
    "            loss2 = self.calcError(X, Y, vector + perturb)\n",
    "            perturb[i] = 0\n",
    "            approx[i] = (loss2 - loss1) / (2 * epsilon)\n",
    "        return self.reconstructMatrices(approx)\n",
    "        \n",
    "    def gradientDescent(self, X, Y, alpha, ciclos=10, checkGradient = False):\n",
    "        \"\"\" Evalúa y ajusta los pesos de la red,\n",
    "        de acuerdo a los datos en X y los resultados\n",
    "        esperados, en Y.\n",
    "        \"\"\"\n",
    "        errores = np.zeros(ciclos)\n",
    "        for i in range(ciclos):\n",
    "            self.backPropagate(X, Y)\n",
    "            Grad_1 = self.Grad_1\n",
    "            Grad_0 = self.Grad_0\n",
    "            if checkGradient:\n",
    "                ApproxT0, ApproxT1 = self.approxGradient(X, Y)\n",
    "                \n",
    "                print(\"Grad 0 = \", Grad_0, end=\"\\n\\n\")\n",
    "                print(\"Approx = \", ApproxT0, end=\"\\n\\n\")\n",
    "                print(\"Diff = \", Grad_0 - ApproxT0, end=\"\\n\\n\")\n",
    "                print()\n",
    "                print(\"Grad 0 = \", Grad_1, end=\"\\n\\n\")\n",
    "                print(\"Approx = \", ApproxT1, end=\"\\n\\n\")\n",
    "                print(\"Diff = \", Grad_1 - ApproxT1, end=\"\\n\\n\")\n",
    "                \n",
    "            self.Theta_1 -= alpha * Grad_1\n",
    "            self.Theta_0 -= alpha * Grad_0\n",
    "            errores[i] = self.error\n",
    "        if ciclos > 1:\n",
    "            plt.plot(np.arange(ciclos), errores)\n",
    "        \n",
    "    def printOutput(self, do_print = True):\n",
    "        data = np.hstack((self.A0.T[:,1:], self.A2.T))\n",
    "        if do_print: print(data)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMi2DiEd0Vgt",
    "outputId": "f8f750fe-7a5d-45a4-b1df-bf754a8bf0b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.69697434],\n",
       "       [0.        , 1.        , 0.71737828],\n",
       "       [1.        , 0.        , 0.70117284],\n",
       "       [1.        , 1.        , 0.72086962]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "xor = XOR()\n",
    "xor.feedForward(X)\n",
    "xor.printOutput(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZN4sIGPu0Vgy",
    "outputId": "2bd6fe24-71fb-4d5b-ea0b-f471a8d27795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77132064]\n",
      " [0.02075195]\n",
      " [0.63364823]\n",
      " [0.74880388]\n",
      " [0.49850701]\n",
      " [0.22479665]\n",
      " [0.19806286]\n",
      " [0.76053071]\n",
      " [0.16911084]]\n",
      "\n",
      "[[0.77132064 0.02075195 0.63364823]\n",
      " [0.74880388 0.49850701 0.22479665]]\n",
      "\n",
      "[[0.19806286 0.76053071 0.16911084]]\n",
      "\n",
      "[[0.77132064 0.02075195 0.63364823]\n",
      " [0.74880388 0.49850701 0.22479665]]\n",
      "\n",
      "[[0.19806286 0.76053071 0.16911084]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(xor.vectorWeights(), end='\\n\\n')\n",
    "print(xor.Theta_0, end='\\n\\n')\n",
    "print(xor.Theta_1, end='\\n\\n')\n",
    "\n",
    "T0, T1 = xor.reconstructMatrices(xor.vectorWeights())\n",
    "print(T0, end='\\n\\n')\n",
    "print(T1, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqec90ew0Vg2",
    "outputId": "e1fa47c0-7dd0-4749-81e0-c714089ba111"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cb7ce339f167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckGradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-519577159ce7>\u001b[0m in \u001b[0;36mgradientDescent\u001b[0;34m(self, X, Y, alpha, ciclos, checkGradient)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mGrad_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrad_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheckGradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mApproxT0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mApproxT1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grad 0 = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrad_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-519577159ce7>\u001b[0m in \u001b[0;36mapproxGradient\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mperturb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mapprox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstructMatrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4) into shape (1)"
     ]
    }
   ],
   "source": [
    "xor.gradientDescent(X, Y, 0.3, 1, checkGradient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWp2m4940Vg5",
    "outputId": "f4a65530-ae53-4a2e-bc6a-dccdbeb46a69"
   },
   "outputs": [],
   "source": [
    "@interact_manual(ciclos = (4_000, 10_000))\n",
    "def trainXOR(ciclos):\n",
    "    xor.gradientDescent(X, Y, 0.5, ciclos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CtqYXrTY0Vg8",
    "outputId": "34cd6786-5227-4b1a-ccff-5376540b1f10"
   },
   "outputs": [],
   "source": [
    "xor.feedForward(X)\n",
    "xor.printOutput()\n",
    "print(np.round(xor.printOutput(False)), end='\\n\\n')\n",
    "\n",
    "print(\"Theta_0 = \", xor.Theta_0, end=\"\\n\\n\")\n",
    "print(\"Theta_1 = \", xor.Theta_1, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NN_XOR.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
